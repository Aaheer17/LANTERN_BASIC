run_name: higher_hidden_dim_noise_linear
dtype: float32

# Model
model_type: shape
energy_model: /project/biocomplexity/fa7sa/calo_dreamer/results/20250625_145756_d2_energy_model_DDPM_epoch_500_RERUN/
model: TBD_DIFF
# Data
hdf5_file: /project/biocomplexity/fa7sa/calochallenge_datasets/dataset_2/dataset_2_1.hdf5
eval_hdf5_file: /project/biocomplexity/fa7sa/calochallenge_datasets/dataset_2/dataset_2_2.hdf5
xml_filename: /project/biocomplexity/fa7sa/calo_dreamer/src/challenge_files/binning_dataset_2.xml

val_frac: 0.15
eps: 1.0e-10
particle_type: electron
eval_dataset: "2"
eval_cut: 15.15e-3
shape: [1, 45, 16, 9]

transforms: {
    ScaleVoxels: {factor: 0.35},
    NormalizeByElayer: {
        ptype: /project/biocomplexity/fa7sa/calo_dreamer/src/challenge_files/binning_dataset_2.xml,
        xml_file: electron
    },
    CutValues: {cut: 1.0e-7},
    SelectiveUniformNoise: {
        noise_width: 0.0e-6,
        cut: True,
        exclusions: [-45, -44, -43, -42, -41, -40, -39, -38, -37,
                     -36, -35, -34, -33, -32, -31, -30, -29, -28,
                     -27, -26, -25, -24, -23, -22, -21, -20, -19,
                     -18, -17, -16, -15, -14, -13, -12, -11, -10,
                      -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1]
    },
ExclusiveLogitTransform: {delta: 1.0e-6, rescale: True},
    StandardizeFromFile: {},
    LogEnergy: {},
    ScaleEnergy: {e_min: 6.907755, e_max: 13.815510},
    AddFeaturesToCond: {split_index: 6480},
    Reshape: {shape: [1, 45, 16, 9]}
}

# Training
lr: 1.e-3
max_lr: 1.e-3
# was 64, changed by Farzana to allow the cuda memory
batch_size: 64
validate_every: 5
use_scheduler: True
lr_scheduler: CosineAnnealing
weight_decay: 1.e-5
betas: [0.9, 0.999]
n_epochs: 800
#n_epochs: 1
cycle_epochs: 800
cycle_pct_start: 0.1
save_interval: 100_001
clip_gradients_to: 100
beta_schedule: 'linear'

# Sampling
sample_periodically: False
sample_every: 10
sample_every_n_samples: 1001
batch_size_sample: 64
n_samples: 100000
solver_kwargs: {method: rk4, options: {step_size: 0.02}}

# Network 
# hidden dim changed from 480 to 240
network: ViT
condition_dim: 46
#patch_shape: [3, 16, 1]
#patch_shape: [3, 4, 3]
#patch_shape: [1, 16, 9]
#patch_shape: [1, 16, 1]
patch_shape: [1, 16, 3]
hidden_dim: 348
depth: 6
num_heads: 6
mlp_ratio: 4.0
augment_batch: False
pos_embedding_coords: cylindrical
learn_pos_embed: True
cos_attn: False
causal_attn: False
coarse: False
prediction_type: noise
# patch_shape: [3, 2, 1]
# hidden_dim: 480
# depth: 8
# num_heads: 8
# mlp_ratio: 4.0
